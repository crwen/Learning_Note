# 数据库复习

## 1. 数据库基础

### 1.1 事务

```text
START TRANSACTION;

/*ROLLBACK [WORK]*/

COMMIT;
```

#### 并发一致性问题

* **更新丢失：**一个事务提交的更新被另外一个事务修改
* **脏读、脏写：**一个事务中会**读取到另一个事务中还没有提交的数据**，如果另一事务最终**回滚**了数据，那么所读取到的数据就是无效的（脏读）。一个事务**修改了另一个未提交事务修改过的数据**，而另一个事务进行了**回滚**，造成事务的更新丢失。
* **不可重复读：**一个事务中可以**读取到另一个事务中已经提交的数据，在同一次事务中对同一数据读取的结果可能不同**。比如 事务 A 读取数据后，事务 B 对数据进行了修改，紧接着事务 A 再次读取数据，发现两次读取的数据不一样了。
* **幻读：**一个事务在**读取数据时，当另一个事务在表中插入了一些新数据时再次读取表时会多出几行**，如同出现了幻觉。比如 事务 A 读取数据后，事务 B 进行了满足条件的插入操作，事务 B 再次读取时，发现多出了一条数据

#### ACID

* 原子性（Atomicity）：
* 一致性（Consistency）：
* 隔离性（Isolation）：
* 持久性（Durability）：

#### 隔离级别

* `READ UNCOMMITTED` 未提交读，一个事务会**读取到另一个事务没有提交的数据**，存在脏读、不可重复读、幻读的问题。
* `READ COMMITTED` 已提交读，一个事务可以**读取到另一个事务已经提交的数据**，解决了脏读的问题，存在不可重复读、幻读的问题。
* `REPEATABLE READ` 可重复读，MySQL 默认的隔离级别，**在一次事务中读取同一个数据结果是一样的**，解决了不可重复读的问题，存在幻读问题。
* `SERIALIZABLE` 可串行化，**每次读都需要获得表级共享锁，读写互相阻塞**，效率低，解决了幻读问题。

### 1.2 理论设计

#### 函数依赖

#### 范式

**1. 第一范式 \(1NF\)**

属性不可分。

**2. 第二范式 \(2NF\)**

每个非主属性完全函数依赖于键码。

**3. 第三范式 \(3NF\)**

非主属性不传递函数依赖于键码。

#### 分库分表

**水平切分**

水平切分又称为 Sharding，它是将同一个表中的记录拆分到多个结构相同的表中。

当一个表的数据不断增多时，Sharding 是必然的选择，它可以将数据分布到集群的不同节点上，从而缓存单个数据库的压力。

![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/63c2909f-0c5f-496f-9fe5-ee9176b31aba.jpg)

Sharding 策略

* 哈希取模：hash \(key\) % N；
* 范围：可以是 ID 范围也可以是时间范围；
* 映射表：使用单独的一个数据库来存储映射关系

Sharding 存在的问题

**1. 事务问题**

使用分布式事务来解决，比如 XA 接口。

**2. 连接**

可以将原来的连接分解成多个单表查询，然后在用户程序中进行连接。

**3. ID 唯一性**

* 使用全局唯一 ID（GUID）
* 为每个分片指定一个 ID 范围
* 分布式 ID 生成器 \(如 Twitter 的 Snowflake 算法\)

**垂直切分**

垂直切分是将一张表按列切分成多个表，通常是按照列的关系密集程度进行切分，也可以利用垂直切分将经常被使用的列和不经常被使用的列切分到不同的表中。

在数据库的层面使用垂直切分将按数据库中表的密集程度部署到不同的库中，例如将原来的电商数据库垂直切分成商品数据库、用户数据库等。

![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/e130e5b8-b19a-4f1e-b860-223040525cf6.jpg)

## 2. 日志

### 2.1 redo log

当有一条记录需要更新时，InnoDB 会先把记录写到 redo log 中，并更新内存。同时 InnoDB 会在适当的时机，将操作记录更新到磁盘。

在更新过程中，redo 日志是先写入 redo log buffer 中的，当事务提交的时候直接写到 redo log 文件中。

redo log 是一块固定的空间

### 2.2 undo log

每条记录在更新的时候都会记录一条回滚记录，通过回滚操作就可以得到前一个状态的值。

**插入**

undo 日志记录主键信息。回滚时，根据主键信息进行删除

**删除**

1. undo 日志记录旧的 `trx_id` 和 `roll_pointer`（方便找到记录在修改前对应的 undo 日志），将记录的 `delete_mask` 标识位设置为 1
2. 事务提交后，将记录从正常记录链表中移除，加入垃圾链表。回滚时，根据 `roll_pointer` 找到 undo 日志进行恢复

![image\_1d6cg2ocf8ctpot13121pb7a9tp.png-36.4kB](https://user-gold-cdn.xitu.io/2019/6/24/16b875afef7f83bf?imageView2/0/w/1280/h/960/format/png/ignore-error/1)

**更新**

**1. 不更新主键**

* 如果更新前后列占用存储空间不变，就地更新
* 任何一列大小发生改变，先删除旧纪录，再插入新纪录

记录 `tri_id` 和 `roll_pointer`，记录共有多少列进行了更新、被更新列更新前的信息

![image\_1d6bbqp2f3q160v1lribq31n0f44.png-141.9kB](https://user-gold-cdn.xitu.io/2019/6/24/16b875b016bf5817?imageView2/0/w/1280/h/960/format/png/ignore-error/1)

**2. 更新主键**

* 旧纪录 `delete_mark`
* 根据更新后列的值创建新纪录，插入到聚簇索引中

### 2.3 bin log

binlog 是 Server 层的，它记录的是逻辑日志，记录的是这个语句的原始逻辑。比如“给 ID = 3 这一行的 c 字段加 1”

binlog 是追加写的，在事务执行过程中，先把日志写到 binlog cache 中，事务提交时，再把 binlog cache 写到 binlog 文件中。

## 3. 锁

### 3.1 全局锁

全局锁会对整个数据库实例加锁。MySQL 提供了一个加全局读锁的方法

```text
Flush tables with read lock
unlock tables;
```

当需要让整个库处于只读状态时（比如全库备份），可以使用这个命令，之后其他线程的数据更新、定义、更新类事务的提交语句会被阻塞。

对于支持事务的执行引擎，可以使用 `mysqldump -single-transaction` 做备份。

### 3.2 表级锁

MySQL 中表级锁有两种：

* 表锁

  ```text
  lock table ... read/write
  ```

  * 读锁：本线程只能读事务，其他线程写操作被阻塞事务
  * 写锁：本线程可以读写事务，其他线程不能读写事务

* 元数据锁（MDL，metadata lock）：MDL 锁不需要显示使用，在访问一个表时会自动加上，其作用是保证读写的正确性。MDL 在事务提交时才释放。
  * 对表做增删改操作，加 MDL 读锁
  * 对表结构变更，加 MDL 写锁

### 3.3 行锁

行锁时针对数据表中行记录的锁，是由引擎层实现的。

![img](https://static001.geekbang.org/resource/image/51/10/51f501f718e420244b0a2ec2ce858710.jpg)

上面的事务 B 的更新语句会阻塞，这就是两阶段锁协议。

**两阶段锁协议**：**行锁是在需要的时候才加上的，但是等到事务结束后才会释放**。所以当事务中需要加锁时，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。

### 3.4 死锁

当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源，就会导致这几个线程都进入无限等待状态，称为死锁。

![img](https://static001.geekbang.org/resource/image/4d/52/4d0eeec7b136371b79248a0aed005a52.jpg)

**死锁策略**

* 等待，直到超时，超时参数可以通过 `innodb_lock_wait-timeout` 设置，默认为 50 s。
* 死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以执行。通过将 `innodb_deadlock_detect` 设置为 on 实现

### 共享锁与排他锁

```text
select k from t where id = 1 lock in share mode;
select k from t where id = 1 for update;
```

### 悲观锁与乐观锁

从程序员的角度看，数据库中的锁又可以分为**悲观锁和乐观锁。**

**悲观锁：**利用数据库的锁机制实现，在整个数据处理过程中都加入了锁，以保持排他性。

**乐观锁：**乐观锁可以利用 CAS 实现，在**操作数据**的时候进行一个比较，按照**当前事务中的数据和数据库表中的该数据是否一致**来决定是否要执行本次操作。

## 4. MVVC（多版本并发控制）

### 4.1 版本链

每次对记录进行改动都会记录一条 undo 日志，每条日志有一个 `roll_pointer` 属性，指向记录的前一个状态，于是这些 undo 日志形成了一个链表

### 4.2 ReadView

MVCC 维护了一个 ReadView 结构，主要包含了当前系统未提交的事务列表 `TRX_IDs` {TRX\_ID\_1, TRX\_ID\_2, ...}，还有该列表的最小值 `TRX_ID_MIN` 和下一个事务 id `TRX_ID_MAX`以及生成该 ReadView 的事务 `CREATOR_TRX_ID`。

* 当前访问`trx_id == creator_trx_id`：标识正在访问当前事务
* 当前访问`trx_id >= min_trx_id`，说明当前事务已经提交，可以访问
* 当前访问`trx_id >= max_trx_id`，说明生成该版本的事务再当前事务生成 ReadView 后才开启，所以不能访问
* 当前访问 `min_trx_id < trx_id < max_trx_id`

  * `trx_id` 在 `m_ids` 列表中，说明没有提交，不能访问
  * `trx_id` 不在  `m_ids` 列表中，说明已经提交。可以访问

  如果某个版本的数据对当前事务不可见，那就顺着版本链找到下一个版本的数据，继续按照上面的规则进行判断。

  **ReadView 生成时机**

  提交读\(`read committed`\)：每次读取数据前生成，**每个 SQL 语句开始执行时创建**

  可重复读\(`repeatable read`\)：视图是在第一次快照读生成的，使用 `start transaction with snapshot` 时，视图是在事务开启时创建的，整个事务期间都用这个视图。

### 4.3 Next-Key Locks

**快照读**：MVCC 的 SELECT 语句会生成一个 ReadView，这个称为快照都

**当前读**：更新数据都是先读后写的，这个读只能读当前的值，称为当前读，查询语句加锁也是当前读

MVCC 只能解决快照读中的幻读，达到你是不能解决当前读的幻读问题

| 事务A | 事务B |
| :---: | :---: |
| begin; |  |
| select \* from t; |  |
|  | insert into t\(k\) values\(100\); |
| update t set k = k + 1; |  |
| select \* from t; |  |
| commit; |  |

MVCC 不能解决幻影读问题，Next-Key Locks 就是为了解决这个问题而存在的。在可重复读（REPEATABLE READ）隔离级别下，使用 MVCC + Next-Key Locks 可以解决幻读问题。

**Gap Lock**

行锁只能锁住行，但是新插入记录这个动作要更新的是记录之间的 “间隙”，间隙锁所得就是两个记录索引之间的间隙。

**Next-Key Locks**

Next-Key Locks 是行锁与 Gap Locks 的结合，在锁定一个记录的同时，页锁定索引之间的间隙。

## 5. MySQL

### 5.1 服务器

### 5.2 存储引擎

#### InnoDB

是 MySQL 默认的事务型存储引擎，只有在需要它不支持的特性时，才考虑使用其它存储引擎。

实现了四个标准的隔离级别，默认级别是可重复读（REPEATABLE READ）。在可重复读隔离级别下，通过多版本并发控制（MVCC）+ Next-Key Locking 防止幻影读。

主索引是聚簇索引，在索引中保存了数据，从而避免直接读取磁盘，因此对查询性能有很大的提升。

内部做了很多优化，包括从磁盘读取数据时采用的可预测性读、能够加快读操作并且自动创建的自适应哈希索引、能够加速插入操作的插入缓冲区等。

支持真正的在线热备份。其它存储引擎不支持在线热备份，要获取一致性视图需要停止对所有表的写入，而在读写混合场景中，停止写入可能也意味着停止读取。

**查找过程**

1. 定位到记录所在的页
2. 从所在页中查找相应的记录

**定位记录所在的页**

![image\_1cacafpso19vpkik1j5rtrd17cm3a.png-158.1kB](https://user-gold-cdn.xitu.io/2019/4/9/16a01bd2a6c7a65f?imageView2/0/w/1280/h/960/format/png/ignore-error/1)

**页内查询**

![image](https://user-gold-cdn.xitu.io/2019/5/8/16a95c10e3449897?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

#### MyISAM

设计简单，数据以紧密格式存储。对于只读数据，或者表比较小、可以容忍修复操作，则依然可以使用它。

提供了大量的特性，包括压缩表、空间数据索引等。

**不支持事务。**

**不支持行级锁，只能对整张表加锁**，读取时会对需要读到的所有表加共享锁，写入时则对表加排它锁。但在表有读取操作的同时，也可以往表中插入新的记录，这被称为并发插入（CONCURRENT INSERT）。

可以手工或者自动执行检查和修复操作，但是和事务恢复以及崩溃恢复不同，可能导致一些数据丢失，而且修复操作是非常慢的。

如果指定了 DELAY\_KEY\_WRITE 选项，在每次修改执行完成时，不会立即将修改的索引数据写入磁盘，而是会写到内存中的键缓冲区，只有在清理键缓冲区或者关闭表的时候才会将对应的索引块写入磁盘。这种方式可以极大的提升写入性能，但是在数据库或者主机崩溃时会造成索引损坏，需要执行修复操作。

**索引**

MyISAM 将数据与索引分开存储，它将表中的记录按照记录的**插入顺序**单独存储在数据文件中，我们可以通过行号快速访问一条记录。

MyISAM 将索引信息存储到另外一个索引文件，它会单独为主键创建一个索引，但是索引的叶子节点中存储的不是完整的用户记录，而是 主键值 + 行号。查询数据时，需要先查询到主键值，然后根据行号查找到对应的行记录

**比较**

* 事务：InnoDB 是事务型的，可以使用 Commit 和 Rollback 语句。
* 并发：MyISAM 只支持表级锁，而 InnoDB 还支持行级锁。
* 外键：InnoDB 支持外键。
* 备份：InnoDB 支持在线热备份。
* 崩溃恢复：MyISAM 崩溃后发生损坏的概率比 InnoDB 高很多，而且恢复的速度也更慢。
* 其它特性：MyISAM 支持压缩表和空间数据索引。

### 5.3 索引

索引（index）是帮助 高效获取数据的**数据结构**（有序）。在数据之外，**数据库系统还维护着满足特定查找算法的数据结构**，这些数据结构以某种方式引用（指向）数据， 这样就可以在这些数据结构上实现高级查找算法，这种数据结构就是索引。

```text
CREATE TABLE 表名(
    col type ,
    ......

    [KEY][INDEX] 索引名(col, col2)
);
ALTER TABLE 表名 DROP [KEY][INDEX] 索引名(col, col2);
ALTER TABLE 表名 ADD [KEY][INDEX] 索引名(col, col2);
```

#### 索引优缺点

优点：

* 提高数据检索的效率，**降低数据库的 IO 成本，将随机 I/O 变为顺序 I/O**。
* 通过索引列对数据进行排序，**降低数据排序的成本**，降低 CPU 的消耗。

劣势：

* 实际上索引也是一张表，该表中保存了主键与索引字段，并指向实体类的记录，所以索引列也是要占用空间的。 
* 虽然索引大大提高了查询效率，同时却也**降低更新表的速度**，如对表进行 INSERT、UPDATE、DELETE。因为更新表时，MySQL **不仅要保存数据，还要保存一下索引文件每次更新添加了索引列的字段**，都会调整因为更新所带来的键值变化后的索引信息。

#### 索引类型

**B-Tree索引**

* 因为存储引擎不用进行全表扫描来获取数据，直接从索引的根节点开始搜索，从而能加快访问数据的速度
* B-Tree 对索引是顺序组织存储的，很适合查找范围数据
* 适用于全键值、键值范围或者键前缀查找 _（根据最左前缀查找）_
* 限制：
  * 对于联合索引来说，如果不是从最左列开始查找，则无法使用索引；
  * 不能跳过索引中的列
  * 范围右边所有列都无法使用索引优化查询

**hash索引**

hash 索引是基于 哈希表实现的，只有精确匹配索引所有的列的查询才有效。

对于每一行数据，存储引擎都会对所有的索引列计算一个哈希码，哈希索引将所有的哈希码存储在索引中，同时在哈希表中保存指向每个数据行的指针。如果多个列的哈希值相同，索引会以链表的方式存放多个记录指针到同一个哈希条目中。在MySQL中，只有Memory引擎显式支持哈希索引。

限制：

* 无法用于排序
* 不支持部分索引列匹配查找，因为hash索引使用索引列的全部内容计算hash值
* 只支持等值查询
* 如果hash 冲突很多，代价大

**空间数据索引（R-Tree）**

MyISAM 表支持空间索引，可以用作地理数据存储。空间索引会从所有维度来索引数据。

**全文索引**

全文索引用于查找文本中的关键词，而不是直接比较是否相等。

#### 索引的区分度

#### B-Tree 索引概念

**聚簇索引**

聚簇索引也称为主键索引，其索引树的叶子节点中存的是**完整的数据记录**，页内的记录按照主键的大小顺序排列，每一层的各个页也根据主键大小顺序排成一个**双向链表**。一个表只能包含一个聚簇索引。因为索引（目录）只能按照一种方法进行排序。

```java
create table User(
    id int primary key,
    uid int not null,
    name varchar(16),
    index (uid)
)engine=InnoD
```

**辅助索引/二级索引**

辅助索引（普通索引）的叶子节点内容是**索引的值和主键的值**。如果要查询其他列的话要根据主键值到聚簇索引中再次回表查询

**唯一索引**

与普通索引没有区别，只是在插入前会判断索引数据是不是唯一的。

**联合索引**

为多个列建立索引。比如建立了 \(A, B\) 索引，各条记录之间先按照 A 排序，如果 A 相同就按照 B 排序。

**覆盖索引**

索引包含所有需要查询的字段的值，不需要进行回表操作。

优点：

* 索引通常远小于数据行的大小，只读取索引能大大减少数据访问量。
* 一些存储引擎（例如 MyISAM）在内存中只缓存索引，而数据依赖于操作系统来缓存。因此，只访问索引可以不使用系统调用（通常比较费时）。
* 对于 InnoDB 引擎，若辅助索引能够覆盖查询，则回表。

**最左匹配**

**前缀索引**

用字段的前段部分数据建立索引，可以更快的去搜索某些数据。`ALTER TABLE 表名 ADD KEY(字段名(N));`当字段时一个很长的字符串时，可以建立前缀索引，比如 blog、text 类型的字段

对于 BLOB、TEXT、VARCHAR 类型的列，必须使用前缀索引，之索引开始的部分字符。

**索引下推**

MySQL5.6 引入的索引下推优化，（联合索引前提）可以在索引遍历过程中，**对索引中包含的其余字段先做判断，直接过滤掉不满足条件的记录，减少回表次数，提升查询效率。**

`select * from user_table where username like '张%' and age > 10`

先找到 username 以 “张” 开头的，然后筛选出 age &gt; 10 的数据，再回表查询

#### 索引失效

1. 违反最左匹配原则
2. 在索引列上做计算、函数、类型转换等操作
3. 范围查找后边的列用不到索引
4. 模糊查询
5. or，一个字段有索引，一个字段没索引，将导致引擎放弃使用索引而进行全表扫描
6. 优化器选错索引

**优化器选错索引**

* 扫描行数
  * 区分度：采样统计，选择 N\(默认20\) 个数据页，统计这些页面的不通知，得到平均值，再乘以页面数。变更数量超过1/M\(默认10\)时重新统计。
  * 扫描行数 + 回表代价。事务没提交，删除行是打标记的，也有可能被算入，`analyze table t` 可以重新统计索引信息

#### 设计原则

* 全值匹配最佳

### change buffer

### 5.4 主从复制

### 5.5 调优

#### 优化数据库访问

**1. 只请求需要的数据量**

* 只返回必要的列，最好不要使用 SELECT \*
* 只返回必要的行：使用 LIMIT 限制返回的数据
* 缓存查询重复的数据，使用缓存避免在数据库中查询

**2. 减少扫描行数**

* 使用覆盖索引
* 慢查询日志，查看是否扫描

数据库查询慢怎么解决

#### sql 优化

* 对查询优化，尽量避免全表扫描，考虑在 where 和 order by 涉及的列上建索引
* 尽量避免在 where 子句中对字段进行空值判断
* 应尽量避免在 where 子句中使用！= 或 &lt;&gt; 操作符，否则将引擎放弃使用索引而进行全表扫描。
* 应尽量避免在 where 子句中使用 or 来连接条件，如果一个字段有索引，一个字段没有索引，将导致引擎放弃使用索引而进行全表扫描

xss 和 csrf

#### expain 字段

* **id**：在⼀个⼤的查询语句中每个 SELECT 关键字都对应⼀个唯⼀的 id ，如 explain select \* from s1 where id = \(select id from s1 where name = 'egon1'\); 第一个 select 的 id 是 1，第二个 select 的 id 是 2。有时候会出现两个 select，但是 id 却都是 1，这是因为优化器把子查询变成了连接查询
* select\_type：select 关键字对应的那个查询的类型，如 SIMPLE,PRIMARY,SUBQUERY,DEPENDENT,SNION
* table：每个查询对应的表名
* **type**：执行查询的访问方法，如 const\(主键索引或者唯一二级索引进行等值匹配的情况下\),ref\(普通的⼆级索引列与常量进⾏等值匹配\),index\(扫描全表索引的覆盖索引\)
* possible\_key：查询中可能用到的索引 _\(可以把用不到的删掉，降低优化器的优化时间\)_
* **key**：查询中用到的索引
* filtered：查询器预测满足下一次查询条件的百分比
* **extra**：表示额外信息，如 Using where,Start temporary,End temporary,Using temporary 等

使用时关心哪些参数

执行计划

extra 的 using indexing 和 using where

## 6. Redis

### 特性

**Redis 为什么块**

* 单线程

### 6.1 数据结构

#### 链表

```c
typedef struct listNode {
    struct listNode *prev;
    struct listNode *next;
    void *value;
}
typeDef struct list {
    listNode *head;
    listNode *tail;
    unsigned long len; // 链表包含元素数量
    void *(*dup)(void *ptr);// 节点值复制函数
    void (*free)(void *ptr);// 节点值释放函数
    int (*match)(void *ptr, void *key);//节点值对比函数
}
```

Redis 中的链表是一个**双向无环链表**，获取前驱节点、后继节点、链表长度的时间复杂度都是 O\(1\)

#### 字典

dictht 是一个散列表结构，使用**拉链法**解决哈希冲突。

```c
typedef struct dictht {
    dictEntry **table;
    unsigned long size;
    unsigned long sizemask;
    unsigned long used;
} dictht;
```

Redis 的字典 dict 中包含两个哈希表 dictht，这是为了方便进行 rehash 操作。在扩容时，将其中一个 dictht 上的键值对 rehash 到另一个 dictht 上面，完成之后释放空间并交换两个 dictht 的角色。

```c
typedef struct dict {
    dictType *type;
    void *privdata;
    dictht ht[2];
    long rehashidx; 
    unsigned long iterators; 
} dict;
```

rehash 操作不是一次性完成，而是采用**渐进方式**，这是为了**避免一次性执行过多的 rehash 操作给服务器带来过大的负担**。

渐进式 rehash 通过记录 dict 的 rehashidx 完成，它从 0 开始，然后每执行一次 rehash 都会递增。

在 rehash 期间，**每次对字典执行添加、删除、查找或者更新操作时，都会执行一次渐进式 rehash。在rehash 期间，添加到字典中的键值对会被保持到 ht\[1\] 中。**

采用渐进式 rehash 会导致字典中的数据分散在两个 dictht 上，因此对字典的查找操作也需要到对应的 dictht 去执行。

#### 跳表

跳跃表是基于多指针有序链表实现的，可以看成多个有序链表。

![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/beba612e-dc5b-4fc2-869d-0b23408ac90a.png)

与红黑树等平衡树相比，跳跃表具有以下优点：

* 插入速度非常快速，因为不需要进行旋转等操作来维护平衡性；
* 更容易实现；
* 支持无锁操作。

#### 压缩列表

### 6.2 键的过期时间

Redis 可以通过 `expire` 或者 `pexpire` 命令为每个键设置过期时间，当键过期时，会自动删除该键。

> `setex` 命令可以在设置一个字符串键的同时为键设置过期时间，但是只能用于字符串

redisDb 结构中有一个 expires 过期字典，保存了数据库中所有键的过期时间。过期字典的键是一个指针，指向间空间中的键对象；过期字典的值是一个 long long 类型的整数，保存了键所指向的数据库键的过期时间

#### 过期键删除策略

**1. 定时删除**

通过使用定时器，定时删除删除过期键。这种方式可以保证过期键会尽可能快地被删除，并释放过期键所占用地内存，对内存是最友好的。

定期删除对 CPU 时间最不友好的，因为在过期键比较多的情况下，删除过期键可能占用相当一部分 CPU 时间；而且 Redis 中的事件事件的实现是无序列表，查找时间复杂度为 O\(n\)。

**2. 惰性删除**

程序在取出键时才对键进行过期检查，这样可以保证删除过期键的操作只会在非做不可的情况下进行，对 CPU 事件来说时最友好的。

惰性删除对内存最不友好，因为内存中可能存在很多过期键，但是得不到释放

**3. 定期删除**

定期删除时定时删除和定期删除的一种这种，它每隔一段时间执行依次删除过期键的操作，并通过限制删除操作执行的时长和频率来减少 CPU 的影响。

**3. Redis 的实现方式**

Redis 将配合使用**定期删除**和**惰性删除**策略，在合理使用 CPU 时间和避免浪费内存空间之间取得平衡。

* 所有**读写数据库的 Redis 命令在执行之前都会调用** `expireIfNeeded` 函数对输入键进行检查，如果键已经过期，就删除。
* 每当 Redis **周期性操作时，调用** `activeExpireCycle` 函数，在规定时间内，分多次遍历各个数据库，从过期字典中随机检查一部分键的过期时间，并删除过期键

**RDB对过期键的策略**

在执行 `SAVE` 或 `BGSAVE` 时，会对键进行检查，排除已过期的键。

载入 RDB 文件时

* 主服务器模式，会对保存的键进行检查，忽略过期键。
* 从服务器模式，载入所有数据。但是数据同步时，从服务器数据会被清空

**AOF对过期键的策略**

* 键过期当时没被删除，不影响
* 键过期被删除，向 AOF 中追加一条 `DEL` 命令来显示记录该键已被删除

AOF 重写时，对键进行检查，已过期的键不会被保存到重写的 AOF 中。

### 6.3 持久化

Redis 有两种持久化方式，分别是 RDB 和 AOF\(Append Only File\)

#### RDB

RDB 会将某一时刻的数据库状态以文件的形式写入到磁盘中。

有三种触发 RDB 的方法，分别是

* `SAVE` 同步命令：`SAVE` 命令会**阻塞** Redis 服务器进程，直到 RDB 文件创建完毕为止。这时客户端发送的所有命令都会被阻塞
* `BGSAVE` 异步命令：`BGSAVE` 命令回 `fork` 出一个进程用于创建 RDB  文件，此时读命令可以正常执行，**写命令会生成该数据的副本**，然后子进程会把这个副本数据写入 RDB 文件
* 自动触发：在配置文件中配置，比如 `save 60 10000`，Redis 服务器默认每隔 100ms 周期性地执行操作函数 `serverCron`，，当满足条件时，会使用 `BGSAVE` 生成 RDB 文件。修改次数与时间由 `dirty` 与 `lastsave` 属性进行维护

#### AOF

AOF 持久化功能的实现可以分为三个步骤：命令追加 \(append\)、文件写入、文件同步 \(sync\)

* **命令追加**：服务器在执行完一个命令后，将被**执行的写命令追加到服务器状态的 `aof_buf` 缓冲区的末尾**。
* **文件写入与同步**：服务器在每次结束一个事件循环之前，调用 `flushAppendOnlyFile` 函数，将缓冲区中的内容写入和保存到 AOF 文件中。

| 选项 | 同步频率 |
| :---: | :---: |
| always | 每个写命令都同步 |
| everysec | 每秒同步一次 |
| no | 让操作系统来决定何时同步 |

**AOF 重写**

随着服务器写请求的增多，AOF 文件会越来越大。Redis 提供了一种将 AOF 重写的特性，能够去除 AOF 文件中的冗余写命令。

AOF 重写时**先从数据库中读取键的值，然后用一条命令去记录键值对**，代替之前记录这个键值对的多条命令。

Redis 将 AOF 重写操作放到**子进程**中执行，子进程带有服务器进程的数据副本，可以在避免使用所的情况下保证数据的安全。

在子进程重写期间，**写命令会写入到发送给 AOF 缓冲区和重写缓冲区**。当 AOF 重写完成后，会将 AOF 重写缓冲区中的所有内容写入到新 AOF 文件中。

#### 混合使用 AOF 与 RDB

Redis 4.0 后开始支持混合使用 AOF 与 RDB。在 RDB 备份期间，使用 AOF 记录写命令，在下一次 RDB 时，清空 AOF 文件。

### 6.4 事务

一个事务包含了多个命令，服务器在执行事务期间，不会改去执行其它客户端的命令请求。

事务中的多个命令被一次性发送给服务器，而不是一条一条发送，这种方式被称为流水线，它可以减少客户端与服务器之间的网络通信次数从而提升性能。

Redis 最简单的事务实现方式是使用 MULTI 和 EXEC 命令将事务操作包围起来。

### 6.5 复制

通过使用 slaveof host port 命令来让一个服务器成为另一个服务器的从服务器。

一个从服务器只能有一个主服务器，并且不支持主主复制。

```text
SLAVEOF 127.0.0.1 6379 // Redis 5.0 之前
REPLICAOF 127.0.0.1 6379
```

#### 连接过程

新版本的 Redis 采用 `PSYNC` 命令来实现复制功能。`PSYNC` 命令有完整重同步（full resynchronization）和部分重同步（partial resynchronization）两种模式。

**完整重同步**

* **同步**
* 从服务器向主服务器发送 `PSYNC` 命令
* 收到 `PSYNC` 的主服务器执行 `BGSAVE` 命令，在后台生成 RDB 文件，并使用一个缓冲区记录从现在开始执行的所有写命令
* 主服务器 `BGSAVE` 命令执行完毕，将 RDB 文件发送给从服务器
* 从服务器接收并载入 RDB 文件，更新自己数据库状态
* 主服务器将缓冲区中的写命令发送给从服务器，从服务器执行这些写命令，从而达到主从一致
* **命令传播**

  主服务器将执行的写命令发送给从服务器，并将写命令复制到积压缓冲区

**部分重同步**

部分重同步用于处理断线后重复制的情况。因为主从服务器保存的数据大部分都是相同的，所以没有必要重新进行完整重同步。为了解决这个问题，Redis 2.8 开始支持部分重同步。部分重同步中，**主服务器可以将从服务器连接断开期间执行的写命令发送给从服务器**

部分重同步功能由三个部分构成：

* **服务器运行 ID**：每个服务器都由自己的运行 ID，当从服务器初次复制时，从服务器会保存主服务器 ID。当从服务器断线重连后，向主服务器发送之前保存的 ID，如果 ID 与主服务器相同，说明是断线重连，否则进行完整重同步。
* **主服务器的复制积压缓冲区**：是一个固定大小的队列。复制积压缓冲区保存着最近传播的写命令，并且记录每个字节相应的复制偏移量。
* **主服务器的复制偏移量和从服务器的复制偏移量**：主从服务器会维持一个复制偏移量。当从服务器重连时，向主服务器发送复制偏移量 offset，如果复制积压缓冲区中还保持着 offset + 1 的数据，进行部分重同步。否则进行执行完整重同步。

#### 主从链

一次全量复制中，对于主库来说，需要完成两个耗时操作：生成 RDB 文件和传输 RDB 文件。如果从库数量很多，就会导致主库忙于 fork 子进程生成 RDB 文件和传输 RDB 文件。因此可以采用 主-从-从 模式，将主库生成的 RDB 和传输 RDB 的压力，以级联的方式分散到从库上

![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/395a9e83-b1a1-4a1d-b170-d081e7bb5bab.png)

#### 心跳检测

在命令传播阶段，从服务器默认会以每秒一次的频率向主服务器发送命令 `REPLCONF ACK <replication_offset>`

这个命令主要有三个作用：

* **检测主从服务器的网络状态**：如果主服务器超过一秒没有收到来自从服务器的 `REPLCONF ACK` 命令，就说明主从之间的连接出现了问题。
* **辅助实现 `min-slaves` 选项**：防止主服务器在不安全的情况下执行功能写命令
* **检测命令丢失**：传播的命令可能会丢失，使用心跳检测可以可以发送命令的丢失。

### 6.6 Sentinel

Sentinel（哨兵）可以监听集群中的服务器，并在主服务器进入下线状态时，自动从从服务器中选举出新的主服务器。可以在配置文件中配置如下信息

```text
sentinel monitor <master-name> <ip> <redis-port> <quorum>
```

Sentinel 主要执行三个任务：监控、选主和通知

**1. 监控**

监控是指哨兵进程在运行时，**周期性（每秒一次）地给所有主从库发送 PING 命令，检测他们是否仍然在线**。如果没有得到响应，就会将其设置为**主观下线**状态。

但是判断为主观下线不能说明真的下线，因为还有误判的可能。**当一定数量的哨兵都判断该服务器处于下线状态后，会将其设置为客观下线状态。**

**2. 选主**

当主服务器被判定为客观下线后，就需要选择新的主库。选主包含两部分：选择主 Sentinel 和选择主服务器

**leader 选举**

当一个主服务器被判断为客观下线时，这个哨兵就可以给其他哨兵发送命令，要求其他哨兵将自己设置为 leader。一个哨兵只能将一个哨兵设置为 leader，**当一个 Sentinel 获得半数以上的投票后，就成为 leader 哨兵**。

如果在给定时限内，没有选举出 leader，就会暂停一段时间，重新开始选举

**选择主服务器**

leader Sentinel 会将已下线主服务器的所有从服务器保存到一个列表中，然后按照以下规则选择主服务器

1. 删除列表中下线或短线的从服务器
2. 删除列表中最近 5s 没有回复过领头 Sentinel 的 INFO 命令的从服务器，保证剩余从服务器都是最近成功进行过通信的
3. 删除与已下线主服务器连接断开超过 `down-after-milliseconds * 10` 毫秒的服务器，保证从服务器没有过早地断开连接，即数据都是比较新的
4. 选择优先级最高的服务器
5. 选择偏移量最大的服务器
6. 选择运行 ID 最小的服务器

**3. 通知**

当新的主服务器出现后，领头 Sentinel 会让已下线的主服务器属下的所有从服务器去复制新的主服务器，并将就的主服务器设置为从服务器。

### 6.7 集群

一个 Redis 集群通常由多个节点组成，可以通过 `CLUSTER MEET` 命令让节点进行握手，握手成功时，节点就会将 ip 和 port 指定的节点添加到节点所在集群中。

```text
CLUSTER MEET 127.0.0.1 6379
```

#### 分片

### 6.8 使用场景

**1. 计数器**

**2. 缓存**

**3. 消息队列**

**4. 会话缓存**

**5. 分布式锁实现**

**6. 其他**

### 6.9 应用问题

#### 数据一致性

**数据一致性**：缓存中有数据，则缓存中的数据需要与数据库中的相同；缓存没有数据，数据库中的值必须是最新值。

* 先写数据库，再删缓存：
  * 如果写数据库成功，删除缓存失败，会读取到旧值
  * 如果在写数据库后，删缓存前读取数据，会读取到旧值。
* 先删缓存，再写数据库：
  * 如果删除缓存成功，写数据库失败，会造成新值丢失，读取到旧值。
  * 如果在删除缓存后，写数据库前读取数据，发现缓存缺失，读数据库旧值，并将旧值写入缓存。（~~延迟双删，更新完数据库后，sleep之后再删一次缓存~~、加锁，分布式锁）

解决方法：

* 重试：把要删除的缓存值或要更新的数据库值暂存到消息队列。如果删除缓存或更新数据库失败，从消息队列中重新读取，再次删除或更新

#### 缓存雪崩

缓存雪崩是指缓存在**同一时刻大量缓存失效**，请求全部转发到数据库，数据库瞬时压力过大雪崩。比如缓存服务器宕机或者缓存过期。

**解决方案**

1. 将缓存失效时间分散开，比如在原有失效时间的基础上加上一个随机值
2. 服务降级

#### 缓存击穿

缓存击穿是指**热点数据失效**，但是大量请求访问热点数据，导致请求打到了数据库而压力激增，影响数据库其他请求的处理。

**解决方案**

1. 对于热点数据不设置过期时间
2. 使用互斥锁，等操作返回成功将数据写入缓存。

#### 缓存穿透

缓存穿透指的是**访问一个不存在的数据**，请求打在数据库上。

**解决方案**

1. 缓存控制或缺省值
2. 布隆过滤器
3. 请求入口前端进行请求合法性检测，过滤恶意请求

**布隆过滤器**

#### 分布式锁

